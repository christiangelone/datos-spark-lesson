{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parcial 2016 2do Cuatrimestre, Ejercicio 2 \n",
    "\n",
    "En este ejercicio queremos programar un sistema que recomiende\n",
    "textos a usuarios en base a sus gustos sobre ciertos términos (palabras).\n",
    "\n",
    "Se cuenta con un RDD de textos de la forma (docId, texto) donde texto\n",
    "es un string de longitud variable. \n",
    "\n",
    "Además contamos con un RDD que\n",
    "indica qué términos le gustan o no a cada usuario de la forma (userId,\n",
    "término, score) por ejemplo (23, “calesita”, -2). \n",
    "\n",
    "Se pide programar en Spark un programa que calcule el score total de cada documento para cada usuario generando un RDD de la forma (userId, docId, score) en donde el score es simplemente la suma de los scores del usuario para\n",
    "los términos que aparecen en el documento. \n",
    "\n",
    "Puede haber términos en los documentos para los cuales no exista score de algunos usuarios, en\n",
    "estos casos simplemente los consideramos neutros (score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    (1, 'pablo honey'),\n",
    "    (2, 'the bends'),\n",
    "    (3, 'ok computer'),\n",
    "    (4, 'kid a'),\n",
    "    (5, 'amnesiac'),\n",
    "    (6, 'hail to the thief'),\n",
    "    (7, 'in rainbows'),\n",
    "    (8, 'the king of limbs'),\n",
    "    (9, 'a moon shaped pool')\n",
    "]\n",
    "\n",
    "scores = [\n",
    "    ('thom', 'pablo', 1),\n",
    "    ('thom', 'honey', 1),\n",
    "    ('martin', 'pablo', -1),\n",
    "    ('martin', 'honey', -1),\n",
    "    ('martin', 'ok', 30),\n",
    "    ('martin', 'computer', 30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "documentsRDD = sc.parallelize(documents)\n",
    "scoresRDD = sc.parallelize(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generamos algo del tipo (word, docId) donde word sera nuestra key\n",
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# llevamos scores a una representacion que nos permita unir la informacion\n",
    "scoresRDDForJoin = scoresRDD.map(lambda a: (a[1],(a[0],a[2])))\n",
    "scoresRDDForJoin.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()])\\\n",
    "    .join(scoresRDDForJoin)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# para poder realizar una acumulacion debemos llevar la informacion a la representacion (docId, userId, score) \n",
    "# y luego realizar una acumulacion de scores\n",
    "# ignorando el score\n",
    "\n",
    "#notese que el K es docId, userId y el V es el score que aporta el termino\n",
    "\n",
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()])\\\n",
    "    .join(scoresRDDForJoin)\\\n",
    "    .map(lambda a: ((a[1][0], a[1][1][0]), a[1][1][1]))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# acumulamos haciendo reduce\n",
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()])\\\n",
    "    .join(scoresRDDForJoin)\\\n",
    "    .map(lambda a: ((a[1][0], a[1][1][0]), a[1][1][1]))\\\n",
    "    .reduceByKey(lambda a,b: a + b)\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# llevamos a la representacion pedida\n",
    "documentsRDD.flatMap(lambda a: [(word, a[0]) for word in a[1].split()])\\\n",
    "    .join(scoresRDDForJoin)\\\n",
    "    .map(lambda a: ((a[1][0], a[1][1][0]), a[1][1][1]))\\\n",
    "    .reduceByKey(lambda a,b: a + b)\\\n",
    "    .map(lambda a: (a[0][0], a[0][1], a[1]))\\\n",
    "    .collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
